---
title: "p8105_hw2_ys3637"
output: github_document
date: "2022-10-03"
---

```{r}
# library all packages that we need at the beginning
library(tidyverse)
library(dplyr)
library(readxl)
```

## Problem 1

This problem focuses on NYC Transit data; in particular, this CSV file contains information related to each entrance and exit for each subway station in NYC. If you’re not familiar with the NYC subway system, keeping a map in mind while looking at these data might help.

### a)

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

```{r}
# read in data from CSV file
NYC_Transit <- read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
# show the first several lines of the original data
head(NYC_Transit)
# clean the data and convert "entry" from char to logical.
NYC_Transit <- NYC_Transit %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude,
         route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))
# show the first several lines of the cleaned data
head(NYC_Transit)
skimr::skim(NYC_Transit)
```

Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

Answer:

This dataset contains 19 variables, including 11 character variables, e.g. line, 6 numeric variables, e.g. station latitude, station longitude, and 2 logical variables, e.g. ada, entry.

After I read in the data, I used clean_names() to make the all the variables name lowercase, and only select line, station_name, station_latitude, station_longitude, route, entry, vending, entrance_type, ada variables. Then I mutated the entry variable from character to logical type. 

There are 1868 rows and 19 columns. The data cannot be considered tidy, since the route variable spread over the table, and does not have its own column.

### b)

Answer the following questions using these data:

How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.

```{r}
NYC_Transit %>% 
  select(station_name, line) %>% 
  distinct() %>% 
  count()
```

Answer: 465 distinct stations.

How many stations are ADA compliant?

```{r}
NYC_Transit %>% 
  select(station_name, line, ada) %>%
  filter(ada == TRUE) %>% 
  distinct() %>% 
  count()
```

Answer: 84 distinct stations are ADA compliant.

What proportion of station entrances / exits without vending allow entrance?

```{r}
# number of station without vending
Non_vending <-
  NYC_Transit %>% 
  select(station_name, line, vending) %>%
  filter(vending == "NO") %>% 
  distinct() %>% 
  count()
# proportion
Non_vending / 465
```

Answer: 21.29% proportion of station entrances / exits without vending allow entrance.

Reformat data so that route number and route name are distinct variables.
How many distinct stations serve the A train? 

```{r}
# converted route8-route11 to character variable
# made the route1 to route11 to be a new route_number variable while the value # under each route made a new value variable route_name
# deleted the prefix of route1 to route11 in order to only contain numbers
# removed all the rows which contains NA in route_name
NYC_Transit_tidy <- NYC_Transit %>% 
  mutate(route8 = as.character(route8), route9 = as.character(route9),
         route10 = as.character(route10), route11 = as.character(route11)) %>% 
  pivot_longer(route1:route11, names_to = "route_number",
               names_prefix = "route", values_to = "route_name") %>% 
  drop_na(route_name)

NYC_Transit_tidy %>% 
  select(station_name, line, route_name) %>%
  filter(route_name == "A") %>% 
  distinct() %>% 
  count()
```

Answer: 60 distinct stations serve the A train.

Of the stations that serve the A train, how many are ADA compliant?

```{r}
NYC_Transit_tidy %>% 
  select(station_name, line, route_name, ada) %>%
  filter(route_name == "A" & ada == TRUE) %>% 
  distinct() %>% 
  count()
```

Answer: Of the stations that serve the A train, 17 distinct stations are ADA compliant.

## Problem 2

This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel

use reasonable variable names

omit rows that do not include dumpster-specific data

round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
# read in data from excel file
Mr_Trash <- read_excel("data/Trash Wheel Collection Data.xlsx",
                       sheet = 'Mr. Trash Wheel', range = 'A2:N550')
# show the first several lines of the original data
head(Mr_Trash)
# clean the data
Mr_Trash <- Mr_Trash %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
# show the first several lines of the cleaned data
head(Mr_Trash)
```

Use a similar process to import, clean, and organize the data for Professor Trash Wheel, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.

```{r}
# read in data from excel file
Professor_Trash <- read_excel("data/Trash Wheel Collection Data.xlsx",
                       sheet = 'Professor Trash Wheel', range = 'A2:M97')
# clean the data
Professor_Trash <- Professor_Trash %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(type_of_wheel = "Professor") %>% 
  select(type_of_wheel, everything())
# show the first several lines of the cleaned data
head(Professor_Trash)
# add the type of wheel to Mr_Trash, make sue year is a numeric var.
Mr_Trash <- Mr_Trash %>% 
  mutate(type_of_wheel = "Mr.", year = as.numeric(year)) %>% 
  select(type_of_wheel, everything())
# combine Mr_Trash and Professor_Trash
Two_Trash <- full_join(Mr_Trash, Professor_Trash)
```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. 

```{r}
# find the # of rows and cols
c(nrow(Two_Trash), ncol(Two_Trash))
# show the first several lines of the data
head(Two_Trash)
# example of the Mr. and Professor trash data when dumpster is 5
example <- Two_Trash %>% 
  filter((type_of_wheel == "Mr." | type_of_wheel == "Professor") & dumpster == 5)
# print out the example
example
# print of the date, and sports balls column of both trash data
example %>% 
  select(type_of_wheel, dumpster, date, sports_balls)
```

Answer:

This dataset contains 15 variables, with original 14 variables in Mr.Trash, and the new char variable that I added--type_of_wheel--which indicates the type of the wheel, e.g. Mr, Professor.

There are total of 641 observations with 15 columns. As the example given above, the two trash wheel datasets are fully joined and they share 14 same variables while under "sports_balls" column, Professor Trash has all NA values.

For available data, what was the total weight of trash collected by Professor Trash Wheel? 

```{r}
Two_Trash %>% 
  select(type_of_wheel, weight_tons) %>% 
  filter(type_of_wheel == "Professor") %>% 
  summarise(sum = sum(weight_tons))
```

Answer: The total weight of trash collected by Professor  Wheel is 190 tons.

What was the total number of sports balls collected by Mr. Trash Wheel in 2020?

```{r}
Two_Trash %>% 
  select(type_of_wheel, year, sports_balls) %>% 
  filter(type_of_wheel == "Mr." & year == 2020) %>% 
  summarise(sum = sum(sports_balls))
```

Answer: The total number of sports balls collected by Mr. Trash Wheel in 2020 is 856.

## Problem 3

This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r}
# read in data from csv file and clean the data 
pols_month <- read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = recode(month, "01" = "Jan",  "02" = "Feb",
                "03" = "Mar", "04" = "Apr", "05" = "May",
                "06" = "Jun", "07" = "Jul", "08" = "Aug",
                "09" = "Sept", "10" = "Oct", "11" = "Nov",
                "12" = "Dec"),
         year = as.numeric(year),
         prez_gop = recode(prez_gop, "1" = "gop",  "2" = "uknown"),
         prez_dem = recode(prez_dem, "1" = "dem",  "2" = "uknown")) %>% 
  pivot_longer(
    c(prez_gop, prez_dem),
    names_to = "prez_side", 
    values_to = "president") %>% 
  filter(president == "gop" | president == "dem" | president == "uknown") %>% 
  select(-prez_side, -day)
# I treated "1" in prez_gop represents republican (gop), and "2" in prez_gop represents uknown, and similarly for prez_dem, then delete all the row contains "0" values in president column.
pols_month  
```

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r}
# read in data from csv file and clean the data 
snp <- read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/")  %>% 
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         centry = ifelse(year >= 50, 1900, 2000),
         year = year + centry) %>% 
  select(year, month, close) %>% 
  arrange(year, month) %>% 
  mutate(month = recode(month, "1" = "Jan",  "2" = "Feb",
                "3" = "Mar", "4" = "Apr", "5" = "May",
                "6" = "Jun", "7" = "Jul", "8" = "Aug",
                "9" = "Sept", "10" = "Oct", "11" = "Nov",
                "12" = "Dec"))
# arrange the snp dataset according to year and month, to make sure it follows pols_month dataset logic
snp
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r}
# read in data from csv file and clean the data 
unemployment <- read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(jan:dec, names_to = "month",
               values_to = "perc_of_unemploymt") %>% 
  mutate(month = str_to_title(month),
         month = recode(month, "Sep" = "Sept"))
unemployment
```

Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r}
snp_pols <- left_join(pols_month, snp, by = c("year", "month"))
total <- left_join(snp_pols, unemployment, by = c("year", "month"))
# print the total joined dataset
total <- total %>% 
  select(year, month, president, close, perc_of_unemploymt, everything())
total
# print the information of 1950 to check the result
total %>% 
  filter(year == 1950)
```

Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

Answer:

For pols_month dataset, its dimension is 822 rows by 9 columns, range of years is from 1947 to 2015, 68 years, and key variables are year, month, the party of president with date corresponding governors/senators/representatives number in both democratic and republican.

For snp dataset, its dimension is 787 rows by 3 columns, range of years is from 1950 to 2015, 65 years, and key variables are year, month, stock market closing value.

For unemployment dataset, its dimension is 816 rows by 3 columns, range of years is from 1948 to 2015, 67 years, and key variables are year, month, unemployment rate.

The resulting dataset is based on the pols_month dataset, I used left join, so all the years and months in pols were remained. Therefore, the result dataset's dimension is 822 rows by 11 columns, range of years is from 1947 to 2015, 68 years, and key variables are year, month, president, ..., and stock market closing value and unemployment rate for corresponding date.
